{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "import en_core_web_sm\n",
    "spc_en = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "course = pd.read_csv(\"archive/course.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "course = course.drop(['Unnamed: 0', 'Course_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_ids = [str(i).zfill(4) for i in range(1, len(course) + 1)]\n",
    "\n",
    "# Thêm cột \"Course_id\" vào DataFrame\n",
    "course.insert(0, 'Course_id', course_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pd.read_csv(\"history.csv\", encoding='latin-1')\n",
    "history\n",
    "data = list(history['History_course_id'].apply(lambda x:x.split(\",\") ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0005</th>\n",
       "      <th>0005</th>\n",
       "      <th>0014</th>\n",
       "      <th>0022</th>\n",
       "      <th>0024</th>\n",
       "      <th>0031</th>\n",
       "      <th>0044</th>\n",
       "      <th>0045</th>\n",
       "      <th>0053</th>\n",
       "      <th>0062</th>\n",
       "      <th>...</th>\n",
       "      <th>3465</th>\n",
       "      <th>3471</th>\n",
       "      <th>3475</th>\n",
       "      <th>3494</th>\n",
       "      <th>3498</th>\n",
       "      <th>3500</th>\n",
       "      <th>3502</th>\n",
       "      <th>3504</th>\n",
       "      <th>3514</th>\n",
       "      <th>Data analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2133</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2134</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2135</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2136</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2137</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2138 rows × 1896 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0005  0005          0014  0022  0024  \\\n",
       "0        0             0     0     0     0   \n",
       "1        0             0     0     0     0   \n",
       "2        0             0     0     0     0   \n",
       "3        0             0     0     0     0   \n",
       "4        0             0     0     0     0   \n",
       "...    ...           ...   ...   ...   ...   \n",
       "2133     0             0     0     0     0   \n",
       "2134     0             0     0     0     0   \n",
       "2135     0             0     0     0     0   \n",
       "2136     0             0     0     0     0   \n",
       "2137     0             0     0     0     0   \n",
       "\n",
       "      0031                                 0044  0045  0053  0062  ... 3465  \\\n",
       "0                                       0     0     0     0     0  ...    0   \n",
       "1                                       0     0     0     0     0  ...    0   \n",
       "2                                       0     0     0     0     0  ...    0   \n",
       "3                                       0     0     0     0     0  ...    0   \n",
       "4                                       0     0     0     0     0  ...    0   \n",
       "...                                   ...   ...   ...   ...   ...  ...  ...   \n",
       "2133                                    0     0     0     0     0  ...    0   \n",
       "2134                                    0     0     0     0     0  ...    0   \n",
       "2135                                    0     0     0     0     0  ...    0   \n",
       "2136                                    0     0     0     0     0  ...    0   \n",
       "2137                                    0     0     0     0     0  ...    0   \n",
       "\n",
       "     3471 3475 3494 3498 3500 3502 3504 3514 Data analysis  \n",
       "0       0    0    0    0    0    0    0    0             0  \n",
       "1       0    0    0    0    0    0    0    0             0  \n",
       "2       0    0    0    0    0    0    0    0             0  \n",
       "3       0    0    0    0    0    0    0    0             0  \n",
       "4       0    0    0    0    0    0    0    0             0  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...           ...  \n",
       "2133    0    0    0    0    0    0    0    0             0  \n",
       "2134    0    0    0    0    0    0    0    0             0  \n",
       "2135    0    0    0    0    0    0    0    0             0  \n",
       "2136    0    0    0    0    0    0    0    0             0  \n",
       "2137    0    0    0    0    0    0    0    0             0  \n",
       "\n",
       "[2138 rows x 1896 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's transform the list, with one-hot encoding\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "a = TransactionEncoder()\n",
    "a_data = a.fit(data).transform(data)\n",
    "df = pd.DataFrame(a_data,columns=a.columns_)\n",
    "df = df.replace(False,0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\mlxtend\\frequent_patterns\\fpcommon.py:110: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 155 combinations | Sampling itemset size 54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.011225</td>\n",
       "      <td>( 0014)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.011225</td>\n",
       "      <td>( 0236)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014032</td>\n",
       "      <td>( 0257)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.012629</td>\n",
       "      <td>( 0272)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.013096</td>\n",
       "      <td>( 0364)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.013096</td>\n",
       "      <td>(2842,  2993,  3108,  3469)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.013096</td>\n",
       "      <td>( 3503,  2993,  3108, 2842)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.013096</td>\n",
       "      <td>( 3469, 2842,  2993,  3503)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.013096</td>\n",
       "      <td>(2842,  3108,  3503,  3469)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.013096</td>\n",
       "      <td>( 3503, 2842,  2993,  3108,  3469)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>194 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      support                            itemsets\n",
       "0    0.011225                             ( 0014)\n",
       "1    0.011225                             ( 0236)\n",
       "2    0.014032                             ( 0257)\n",
       "3    0.012629                             ( 0272)\n",
       "4    0.013096                             ( 0364)\n",
       "..        ...                                 ...\n",
       "189  0.013096         (2842,  2993,  3108,  3469)\n",
       "190  0.013096         ( 3503,  2993,  3108, 2842)\n",
       "191  0.013096         ( 3469, 2842,  2993,  3503)\n",
       "192  0.013096         (2842,  3108,  3503,  3469)\n",
       "193  0.013096  ( 3503, 2842,  2993,  3108,  3469)\n",
       "\n",
       "[194 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df\n",
    "apriori_t = apriori(df2, min_support = 0.01, use_colnames = True, verbose = 1)\n",
    "apriori_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's view our interpretation values using the Associan rule function.\n",
    "df_ar = association_rules(apriori_t, metric = \"confidence\", min_threshold = 0.6)\n",
    "df_ar[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "antecedents: neural network deep learning\n"
     ]
    }
   ],
   "source": [
    "result = course.loc[course['Course_id'] == \"0992\"]['Course Name'].iloc[0]\n",
    "print('antecedents:', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, antecedents in enumerate(df_ar['antecedents']):\n",
    "    if isinstance(antecedents, frozenset):\n",
    "        antecedents = list(antecedents)\n",
    "    antecedent_ids = ','.join(map(str, antecedents)).strip()  # Chuyển thành danh sách và tách các ID\n",
    "\n",
    "    antecedent_names = []\n",
    "    for antecedent_id in antecedent_ids.split(','):\n",
    "        antecedent_id = antecedent_id.strip()\n",
    "        result = course.loc[course['Course_id'] == antecedent_id]['Course Name'].iloc[0]\n",
    "        antecedent_names.append(result)\n",
    "\n",
    "    antecedent_names_str = ', '.join(antecedent_names)\n",
    "\n",
    "    print(n)\n",
    "    print('antecedents:', antecedent_names_str)\n",
    "\n",
    "    consequents = df_ar['consequents'][n]\n",
    "    if isinstance(consequents, frozenset):\n",
    "        consequents = list(consequents)\n",
    "    consequent_ids = ','.join(map(str, consequents)).strip()  # Chuyển thành danh sách và tách các ID\n",
    "\n",
    "    consequent_names = []\n",
    "    for consequent_id in consequent_ids.split(','):\n",
    "        consequent_id = consequent_id.strip()\n",
    "        result = course.loc[course['Course_id'] == consequent_id]['Course Name'].iloc[0]\n",
    "        consequent_names.append(result)\n",
    "\n",
    "    consequent_names_str = ', '.join(consequent_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_courses(enrolled_courses, df_ar, num_recommendations=5):\n",
    "    # Tạo một danh sách để lưu trữ các khoá học được đề xuất\n",
    "    recommended_courses = []\n",
    "\n",
    "    # Duyệt qua từng tập luật kết hợp trong df_ar\n",
    "    for index, row in df_ar.iterrows():\n",
    "        antecedents = row['antecedents']\n",
    "        consequents = row['consequents']\n",
    "\n",
    "        # Chuyển các ID trong antecedents thành các ID không có khoảng cách\n",
    "        antecedents_cleaned = [course_id.replace(\" \", \"\") for course_id in antecedents]\n",
    "\n",
    "        # Kiểm tra nếu có ít nhất một khoá học từ antecedents có trong danh sách enrolled_courses\n",
    "        if any(course_id in antecedents_cleaned for course_id in enrolled_courses):\n",
    "            # Lấy danh sách các khoá học trong consequents\n",
    "            recommended_courses.extend(consequents)\n",
    "\n",
    "    # Loại bỏ các khoá học đã đăng ký và lặp lại\n",
    "    recommended_courses = list(set(recommended_courses) - set(enrolled_courses))\n",
    "\n",
    "    # Chọn một số lượng giới hạn của khoá học để đề xuất\n",
    "    if len(recommended_courses) > num_recommendations:\n",
    "        recommended_courses = recommended_courses[:num_recommendations]\n",
    "\n",
    "    return recommended_courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0685', '0819', '2924']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enrolled_courses = [\"0966\", \"1677\", \"1109\"]\n",
    "# ['1801', \"0001\",\"3356\"]\n",
    "\n",
    "\n",
    "# Đề xuất các khoá học dựa trên danh sách đã đăng ký và bảng df_ar\n",
    "recommended_courses = recommend_courses(enrolled_courses, df_ar)\n",
    "course_dict = dict(zip(course['Course_id'], course['Course Name']))\n",
    "result =[]\n",
    "for course_id in enrolled_courses:\n",
    "    clean_course_id = course_id.replace(\" \", \"\")  # Loại bỏ dấu cách\n",
    "    course_name = course_dict.get(clean_course_id, 'Not Found') \n",
    "for course_id in recommended_courses:\n",
    "    clean_course_id = course_id.replace(\" \", \"\")  # Loại bỏ dấu cách\n",
    "    course_name = course_dict.get(clean_course_id, 'Not Found')  # Lấy tên khoá học từ từ điển course_dict\n",
    "    \n",
    "    # Kiểm tra xem khoá học đã được đăng ký hay chưa\n",
    "    if clean_course_id not in enrolled_courses:\n",
    "        result.append(clean_course_id)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0999'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def zip4id(id):\n",
    "    stringid = str(id)\n",
    "    \n",
    "    if len(stringid) < 4:\n",
    "        stringid = '0' * (4 - len(stringid)) + stringid\n",
    "    \n",
    "    return stringid\n",
    "zip4id(999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enrolled Courses:\n",
      "- interactive word embedding use word vec plotly (ID: 0966)\n",
      "- nlp twitter sentiment analysis (ID: 1677)\n",
      "- sentiment analysis deep learning use bert (ID: 1109)\n"
     ]
    }
   ],
   "source": [
    "print(\"Enrolled Courses:\")\n",
    "for course_id in enrolled_courses:\n",
    "    clean_course_id = course_id.replace(\" \", \"\")  # Loại bỏ dấu cách\n",
    "    course_name = course_dict.get(clean_course_id, 'Not Found')  # Lấy tên khoá học từ từ điển course_dict\n",
    "    print(f\"- {course_name} (ID: {clean_course_id})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommend Courses:\n",
      "- transfer learn nlp tensorflow hub (ID: 2497)\n"
     ]
    }
   ],
   "source": [
    "print(\"Recommend Courses:\")\n",
    "for course_id in recommended_courses:\n",
    "    clean_course_id = course_id.replace(\" \", \"\")  # Loại bỏ dấu cách\n",
    "    course_name = course_dict.get(clean_course_id, 'Not Found')  # Lấy tên khoá học từ từ điển course_dict\n",
    "    \n",
    "    # Kiểm tra xem khoá học đã được đăng ký hay chưa\n",
    "    if clean_course_id not in enrolled_courses:\n",
    "        print(f\"- {course_name} (ID: {clean_course_id})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\administrator\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\administrator\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "DEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\administrator\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\administrator\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "DEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\administrator\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\administrator\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "DEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers\n",
    "!pip install -q datasets tqdm pandas\n",
    "!pip install -q sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grammar Error Corection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "# model_name = 'deep-learning-analytics/GrammarCorrector'\n",
    "model_name = 't5_gec_model_03/t5_gec_model_03' # model path\n",
    "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n",
    "\n",
    "# def correct_grammar(input_text,num_return_sequences):\n",
    "#   batch = tokenizer([input_text],truncation=True,padding='max_length',max_length=64, return_tensors=\"pt\").to(torch_device)\n",
    "#   translated = model.generate(**batch,max_length=64,num_beams=4, num_return_sequences=num_return_sequences, temperature=1.5)\n",
    "#   tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "#   return tgt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_grammar(input_text,num_return_sequences):\n",
    "  batch = tokenizer([input_text],truncation=True,padding='max_length',max_length=64, return_tensors=\"pt\").to(torch_device)\n",
    "  translated = model.generate(**batch,max_length=64,num_beams=4, num_return_sequences=num_return_sequences, temperature=1.5)\n",
    "  tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "  return tgt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<span>he</span> <span>is</span> <span style='color: red;'>a</span> <span>teacher</span>\n"
     ]
    }
   ],
   "source": [
    "def mark_text(input_text, corrected_text):\n",
    "    # Tách từng từ trong hai câu\n",
    "    input_words = input_text.split()\n",
    "    corrected_words = corrected_text.split()\n",
    "    \n",
    "    result = []\n",
    "\n",
    "    # Duyệt qua từng từ trong hai câu\n",
    "    for input_word, corrected_word in zip(input_words, corrected_words):\n",
    "        # So sánh từ hiện tại trong hai câu\n",
    "        if input_word == corrected_word:\n",
    "            # Nếu từ giống nhau, thêm vào chuỗi kết quả với thẻ <span> bình thường\n",
    "            result.append(f\"<span>{input_word}</span>\")\n",
    "        else:\n",
    "            # Nếu từ khác nhau, thêm vào chuỗi kết quả với thẻ <span> màu đỏ\n",
    "            result.append(f\"<span style='color: red;'>{corrected_word}</span>\")\n",
    "\n",
    "    # Kết hợp chuỗi kết quả thành một chuỗi duy nhất, thêm khoảng trắng giữa các thẻ <span>\n",
    "    marked_text = ' '.join(result)\n",
    "\n",
    "    return marked_text\n",
    "\n",
    "corrected_text = \"he is a teacher\"\n",
    "input_text = \"he is an teacher\"\n",
    "\n",
    "marked_result = mark_text(input_text, corrected_text)\n",
    "print(marked_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['summary: I enjoy writing articles on AI and I also enjoy writing articles on AI.',\n",
       " 'Summary: I enjoy writing articles on AI and I also enjoy writing articles on AI.',\n",
       " 'summary: I enjoy writing articles on AI and I also enjoyed writing articles on AI.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = \"summary: I am enjoys, writtings Articles ons AI and I also enjoyed write articling on AI.\"\n",
    "num_return_sequences = 3 # Số lượng câu generate\n",
    "corrected_text = correct_grammar(input_text, num_return_sequences)\n",
    "corrected_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['summary: I enjoy writing articles on AI and I also enjoy writing articles on AI.',\n",
       " 'Summary: I enjoy writing articles on AI and I also enjoy writing articles on AI.',\n",
       " 'summary: I enjoy writing articles on AI and I also enjoyed writing articles on AI.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrected_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Generation and Fact - Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fitz  # PyMuPDF\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "import json\n",
    "\n",
    "model_name = \"t5-small\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13876\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import textract\n",
    "\n",
    "# Đọc nội dung của tài liệu PDF\n",
    "text = textract.process('Report.pdf', encoding='utf-8')\n",
    "\n",
    "# Sử dụng biểu thức chính quy để cắt thành các đoạn văn\n",
    "all_paragraphs = re.split(r'\\s{2,}', text.decode('utf-8'))\n",
    "num_paragraph= len(text)\n",
    "print(num_paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_para = []\n",
    "list_para = [para for para in all_paragraphs if len(para.split()) >= 20] # list of paragraphs which have more than 20 words\n",
    "len(list_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize paragraph using t5 model\n",
    "\n",
    "summaries = []\n",
    "for i,paragraph in enumerate(list_para):\n",
    "    input_text = \"summarize: \" + paragraph\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    summary_ids = model.generate(input_ids, max_length=150, min_length=50, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    summaries.append(summary)\n",
    "    \n",
    "    # if i==3: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abstract. This paper aims to develop a system that will help in recommendation of courses for an upcoming semester based on the performance of previous semesters.',\n",
       " \"It has always been a tough choice for the students to choose the courses in different semesters in which there is possibility to score good grades apart from the interest in the course. IIIT-Delhi offers variety of courses with mandatory courses in first 4 semesters (with exception of 2 to 3 electives) and all elective courses from fifth semester onwards. Hence, choosing the courses based on the verbal recommendation from the seniors, instructors and fellowmates becomes a hectic task. For easing this process of course recommendation for an upcoming semester, we have developed a system which deploys simple yet powerful recommendation techniques such as auto-encoders, hybrid matrix factorization and similarity based approaches. It is a GUI based system which takes an input of student's ID (which is stored in the backend database) and semester for which the student wants to get the recommendation. Then, it outputs the top 5 courses that the student can choose based on his/her performance in previous semesters. Also, a confidence score is provided for each recommended course.\",\n",
       " 'The dataset has been acquired from the official IIIT-Delhi academics department for the students of 7 Computer Science passout batches. The dataset consists 739 students and 306 subjects with mapping of each student to the grades for each course the student has taken throughout the duration of their degree. The courses are spread over 8 semesters (also including the courses offered to student with extended semester). The fields in the dataset include Serial Number(SN), Roll Number(anonymized) of the student, Batch/Term Code in which the course was offered, Course Code, Course name, Credit offered for the course, Grade obtained by particular student in the course, SPI (Semester Percentile Index) - Average GPA(Grade Point Average) for the current semester and CPI (Cummulative Percentile Index) - Overall GPA.',\n",
       " 'The data is processed from CSV format to JSON format. Each student is mapped to all the courses with the grade and semester in which the course was offered. If the student has taken the course, then the course key(under the particular student key) will have the corresponding grade obtained in the course and the semester in which the course was offered. Each user and course is mapped to a unique integer ID. Incomplete courses, courses for which leave application was given by the student and courses with grade W(weak) are given grade score 0. Online courses with grade S are given grade score as 10 while with X are given grade score 0. For creation of train and test matrices we included only courses that were offered in first 8 semesters as any semester beyond that signifies the presence of backlog or extended semester. For such cases we took the maximum grade score provided to the student in a particular course including all extended semesters and backlogs. Every course has a list of semesters in which it was offered as the same course can be floated in more than 1 semester. Various split ratios were considered and 5 fold cross validation was done for creating the matrices. Test matrix only considered the student-course pair for courses in 5th, 6th 7th and 8th semesters.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_para[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge into result \n",
    "\n",
    "result = [{\"paragraph\": list_para[i], \"summary\": summaries[i]} for i in range(len(summaries))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'paragraph': 'Abstract. This paper aims to develop a system that will help in recommendation of courses for an upcoming semester based on the performance of previous semesters.',\n",
       "  'summary': 'this paper aims to develop a system that will help in recommendation of courses for an upcoming semester based on the performance of previous semesters. this paper aims to develop a system that will help in recommendation of courses based on the performance of previous semesters.'},\n",
       " {'paragraph': \"It has always been a tough choice for the students to choose the courses in different semesters in which there is possibility to score good grades apart from the interest in the course. IIIT-Delhi offers variety of courses with mandatory courses in first 4 semesters (with exception of 2 to 3 electives) and all elective courses from fifth semester onwards. Hence, choosing the courses based on the verbal recommendation from the seniors, instructors and fellowmates becomes a hectic task. For easing this process of course recommendation for an upcoming semester, we have developed a system which deploys simple yet powerful recommendation techniques such as auto-encoders, hybrid matrix factorization and similarity based approaches. It is a GUI based system which takes an input of student's ID (which is stored in the backend database) and semester for which the student wants to get the recommendation. Then, it outputs the top 5 courses that the student can choose based on his/her performance in previous semesters. Also, a confidence score is provided for each recommended course.\",\n",
       "  'summary': 'IIIT-Delhi offers variety of courses with mandatory courses in first 4 semesters. all elective courses from fifth semester onwards become a hectic task. it deploys simple yet powerful recommendation techniques such as auto-encoders.'},\n",
       " {'paragraph': 'The dataset has been acquired from the official IIIT-Delhi academics department for the students of 7 Computer Science passout batches. The dataset consists 739 students and 306 subjects with mapping of each student to the grades for each course the student has taken throughout the duration of their degree. The courses are spread over 8 semesters (also including the courses offered to student with extended semester). The fields in the dataset include Serial Number(SN), Roll Number(anonymized) of the student, Batch/Term Code in which the course was offered, Course Code, Course name, Credit offered for the course, Grade obtained by particular student in the course, SPI (Semester Percentile Index) - Average GPA(Grade Point Average) for the current semester and CPI (Cummulative Percentile Index) - Overall GPA.',\n",
       "  'summary': 'the dataset has been acquired from the official IIIT-Delhi academics department for the students of 7 Computer Science passout batches. the dataset consists 739 students and 306 subjects with mapping of each student to the grades for each course the student has taken throughout the duration of their degree.'},\n",
       " {'paragraph': 'The data is processed from CSV format to JSON format. Each student is mapped to all the courses with the grade and semester in which the course was offered. If the student has taken the course, then the course key(under the particular student key) will have the corresponding grade obtained in the course and the semester in which the course was offered. Each user and course is mapped to a unique integer ID. Incomplete courses, courses for which leave application was given by the student and courses with grade W(weak) are given grade score 0. Online courses with grade S are given grade score as 10 while with X are given grade score 0. For creation of train and test matrices we included only courses that were offered in first 8 semesters as any semester beyond that signifies the presence of backlog or extended semester. For such cases we took the maximum grade score provided to the student in a particular course including all extended semesters and backlogs. Every course has a list of semesters in which it was offered as the same course can be floated in more than 1 semester. Various split ratios were considered and 5 fold cross validation was done for creating the matrices. Test matrix only considered the student-course pair for courses in 5th, 6th 7th and 8th semesters.',\n",
       "  'summary': 'the data is processed from CSV format to JSON format. each student is mapped to all the courses with the grade and semester in which the course was offered. if the student has taken the course, then the course key will have the corresponding grade obtained in the course and the semester in which the course was offered.'},\n",
       " {'paragraph': 'Fig. 1: Top 5 elective courses. (CSE535 - Mobile Computing, CSE506 - Data Mining, CSE345 - Foundation of Security, CSE300 - Software Engineering, FIN401 - Foundations of Finance )',\n",
       "  'summary': 'CSE535 - Mobile Computing, CSE506 - Data Mining, CSE345 - Foundation of security, CSE300 - Software Engineering, FIN401 - Foundations of finance. FIN401 - foundations of finance.'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\n"
     ]
    }
   ],
   "source": [
    "# Clone this responsitory for questions generator\n",
    "# %cd question_generator\n",
    "# !git clone https://github.com/amontgomerie/question_generator!git clone https://github.com/amontgomerie/question_generator\n",
    "!pip install -r requirements.txt -qq\n",
    "# !python run_qg.py --text_file question_generator/articles/twitter_hack.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import file from another folder\n",
    "import sys\n",
    "# caution: path[0] is reserved for script path (or '' in REPL)\n",
    "sys.path.insert(1, 'question_generator')\n",
    "\n",
    "from questiongenerator import QuestionGenerator\n",
    "qg = QuestionGenerator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating questions...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\generation\\utils.py:1346: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating QA pairs...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = result[2][\"summary\"]\n",
    "q  = qg.generate(text, num_questions=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'how many students have taken the course?',\n",
       "  'answer': 'the dataset consists 739 students and 306 subjects with mapping of each student to the grades for each course the student has taken throughout the duration of their degree.'},\n",
       " {'question': 'how many students have taken the iitt?',\n",
       "  'answer': 'the dataset has been acquired from the official IIIT-Delhi academics department for the students of 7 Computer Science passout batches.'},\n",
       " {'question': 'how many subjects do students have taken?',\n",
       "  'answer': [{'answer': '7 Computer Science', 'correct': False},\n",
       "   {'answer': '739', 'correct': False},\n",
       "   {'answer': '306', 'correct': True}]}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dataset has been acquired from the official IIIT-Delhi academics department for the students of 7 Computer Science passout batches. the dataset consists 739 students and 306 subjects with mapping of each student to the grades for each course the student has taken throughout the duration of their degree.\n",
      "how many students have taken the course?\n",
      "how many students have taken the iitt?\n",
      "how many subjects do students have taken?\n"
     ]
    }
   ],
   "source": [
    "print(text)\n",
    "for i in range(len(q)): print(q[i][\"question\"]) #  7 Computer Science passout batches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fact -check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassificationModel(nn.Module):\n",
    "    def __init__(self, bert_model_name, num_labels):\n",
    "        super(BERTClassificationModel, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size * 2, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = torch.cat((outputs.last_hidden_state[:, 0, :], outputs.last_hidden_state[:, -1, :]), dim=1)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "model_path = \"bert_classification_model.pth\"\n",
    "# Tạo mô hình mới\n",
    "loaded_model = BERTClassificationModel('bert-base-uncased', num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_tokenizer = BertTokenizer.from_pretrained(\"tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    loaded_model.load_state_dict(torch.load(model_path))\n",
    "else:\n",
    "    loaded_model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')), strict=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "premise_text : The likelihood is 100% \n",
      " hypothesis_text : Maybe the probability is 100%\n",
      "Predicted Label: entailment\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 128\n",
    "def predict_premise_hypothesis(premise_text, hypothesis_text, model, tokenizer):\n",
    "    # Chuẩn bị dữ liệu đầu vào cho mô hình\n",
    "    inputs = tokenizer(premise_text, hypothesis_text, padding=True, truncation=True, max_length=max_seq_length, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"].to(device)\n",
    "    attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "\n",
    "    # Dự đoán\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids, attention_mask)\n",
    "        probabilities = torch.softmax(logits, dim=1)\n",
    "        predicted_label = torch.argmax(probabilities, dim=1).item()\n",
    "\n",
    "    return predicted_label\n",
    "\n",
    "pre = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "# Sử dụng hàm predict_premise_hypothesis để dự đoán\n",
    "premise_text = \"The likelihood is 100%\"\n",
    "hypothesis_text = \"Maybe the probability is 100%\"\n",
    "predicted_label = predict_premise_hypothesis(premise_text, hypothesis_text, loaded_model, loaded_tokenizer)\n",
    "\n",
    "print(\"premise_text :\", premise_text, \"\\n\", \"hypothesis_text :\", hypothesis_text)\n",
    "print(\"Predicted Label:\", pre[predicted_label])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "premise_text : The dataset had acquired for the student of 7 computer science \n",
      " hypothesis_text : the dataset has been acquired from the official IIIT-Delhi academics department for the students of 7 Computer Science passout batches. the dataset consists 739 students and 306 subjects with mapping of each student to the grades for each course the student has taken throughout the duration of their degree.\n",
      "Predicted Label: entailment\n"
     ]
    }
   ],
   "source": [
    "premise_text = \"The dataset had acquired for the student of 7 computer science\"\n",
    "hypothesis_text = result[2][\"summary\"]\n",
    "\n",
    "predicted_label = predict_premise_hypothesis(premise_text, hypothesis_text, loaded_model, loaded_tokenizer)\n",
    "print(\"premise_text :\", premise_text, \"\\n\", \"hypothesis_text :\", hypothesis_text)\n",
    "print(\"Predicted Label:\", pre[predicted_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Mở tệp CSV để đọc\n",
    "with open('mdl_assign.csv', newline='') as csvfile:\n",
    "    # Tạo đối tượng đọc CSV\n",
    "    csvreader = csv.reader(csvfile)\n",
    "    \n",
    "    # Đọc tiêu đề từ dòng đầu tiên của tệp CSV\n",
    "    headers = next(csvreader)\n",
    "    \n",
    "for header in headers:\n",
    "    globals()[header] = 1     # Nếu bạn muốn thêm vào danh sách, hãy sử dụng:\n",
    "  \n",
    "print(id)      # header_list.append(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_3508/82547003.py:6: DeprecationWarning: Please use `csr_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csr` namespace is deprecated.\n",
      "  loaded_model = pickle.load(open('trained_model.sav', 'rb'))\n",
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator SVC from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator CountVectorizer from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request, redirect, url_for, flash, jsonify\n",
    "from flask_sqlalchemy import SQLAlchemy\n",
    "import pickle\n",
    "import csv\n",
    "\n",
    "loaded_model = pickle.load(open('trained_model.sav', 'rb'))\n",
    "\n",
    "vector = pickle.load(open('vector_conv.sav', 'rb'))\n",
    "\n",
    "app = Flask(__name__)\n",
    "app.secret_key = \"Secret Key\"\n",
    "\n",
    "app.config[\"SQLALCHEMY_DATABASE_URI\"] = 'mysql://root:''@localhost/moodle'\n",
    "app.config[\"SQLALCHEMY_TRACK_MODIFICATIONS\"] = False\n",
    "\n",
    "db = SQLAlchemy(app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name',\n",
       " 'intro',\n",
       " 'introformat',\n",
       " 'alwaysshowdescription',\n",
       " 'nosubmissions',\n",
       " 'submissiondrafts',\n",
       " 'sendnotifications',\n",
       " 'sendlatenotifications',\n",
       " 'duedate',\n",
       " 'allowsubmissionsfromdate',\n",
       " 'grade',\n",
       " 'timemodified',\n",
       " 'requiresubmissionstatement',\n",
       " 'completionsubmit',\n",
       " 'cutoffdate',\n",
       " 'gradingduedate',\n",
       " 'teamsubmission',\n",
       " 'requireallteammemberssubmit',\n",
       " 'teamsubmissiongroupingid',\n",
       " 'blindmarking',\n",
       " 'hidegrader',\n",
       " 'revealidentities',\n",
       " 'attemptreopenmethod',\n",
       " 'maxattempts',\n",
       " 'markingworkflow',\n",
       " 'markingallocation',\n",
       " 'sendstudentnotifications',\n",
       " 'preventsubmissionnotingroup',\n",
       " 'activity',\n",
       " 'activityformat',\n",
       " 'timelimit',\n",
       " 'submissionattachments']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mdl_assign(db.Model):\n",
    "    id = db.Column(db.Integer, primary_key = True)\n",
    "    course = db.Column(db.String(100))\n",
    "    name = db.Column(db.String(100))\n",
    "    intro = db.Column(db.String(100))\n",
    "    introformat = db.Column(db.String(100))\n",
    "    alwaysshowdescription = db.Column(db.String(100))\n",
    "    nosubmissions = db.Column(db.String(100))\n",
    "    submissiondrafts = db.Column(db.String(100))\n",
    "    sendnotifications = db.Column(db.String(100))\n",
    "    sendlatenotifications = db.Column(db.String(100))\n",
    "    duedate = db.Column(db.String(100))\n",
    "    allowsubmissionsfromdate = db.Column(db.String(100))\n",
    "    grade = db.Column(db.String(100))\n",
    "    timemodified = db.Column(db.String(100))\n",
    "    requiresubmissionstatement = db.Column(db.String(100))\n",
    "    completionsubmit = db.Column(db.String(100))\n",
    "    cutoffdate = db.Column(db.String(100))\n",
    "    gradingduedate = db.Column(db.String(100))\n",
    "    teamsubmission = db.Column(db.String(100))\n",
    "    requireallteammemberssubmit = db.Column(db.String(100))\n",
    "    teamsubmissiongroupingid = db.Column(db.String(100))\n",
    "    blindmarking = db.Column(db.String(100))\n",
    "    hidegrader = db.Column(db.String(100))\n",
    "    revealidentities = db.Column(db.String(100))\n",
    "    attemptreopenmethod = db.Column(db.String(100))\n",
    "    maxattempts = db.Column(db.String(100))\n",
    "    markingworkflow = db.Column(db.String(100))\n",
    "    markingallocation = db.Column(db.String(100))\n",
    "    sendstudentnotifications = db.Column(db.String(100))\n",
    "    preventsubmissionnotingroup = db.Column(db.String(100))\n",
    "    activity = db.Column(db.String(100))\n",
    "    activityformat = db.Column(db.String(100))\n",
    "    timelimit = db.Column(db.String(100))\n",
    "    submissionattachments = db.Column(db.String(100))\n",
    "    def __init__(self, id, course, name, intro, introformat, alwaysshowdescription, nosubmissions, submissiondrafts, \n",
    "    sendnotifications, sendlatenotifications, duedate, allowsubmissionsfromdate, grade, timemodified,requiresubmissionstatement, completionsubmit, cutoffdate,\n",
    "    gradingduedate, teamsubmission, requireallteammemberssubmit, teamsubmissiongroupingid, blindmarking, hidegrader, revealidentities, attemptreopenmethod, maxattempts,\n",
    "    markingworkflow, markingallocation, sendstudentnotifications, preventsubmissionnotingroup, activity, activityformat, timelimit, submissionattachments):\n",
    "        self.id = id\n",
    "        self.course = course\n",
    "        self.name = name\n",
    "        self.intro = intro\n",
    "        self.introformat = introformat\n",
    "        self.alwaysshowdescription = alwaysshowdescription\n",
    "        self.nosubmissions = nosubmissions\n",
    "        self.submissiondrafts = submissiondrafts\n",
    "        self.sendnotifications = sendnotifications\n",
    "        self.sendlatenotifications = sendlatenotifications\n",
    "        self.duedate = duedate\n",
    "        self.allowsubmissionsfromdate = allowsubmissionsfromdate\n",
    "        self.grade = grade\n",
    "        self.timemodified = timemodified\n",
    "        self.requiresubmissionstatement = requiresubmissionstatement\n",
    "        self.completionsubmit = completionsubmit\n",
    "        self.cutoffdate = cutoffdate\n",
    "        self.gradingduedate = gradingduedate\n",
    "        self.teamsubmission = teamsubmission\n",
    "        self.requireallteammemberssubmit = requireallteammemberssubmit\n",
    "        self.teamsubmissiongroupingid = teamsubmissiongroupingid\n",
    "        self.blindmarking = blindmarking\n",
    "        self.hidegrader = hidegrader\n",
    "        self.revealidentities = revealidentities\n",
    "        self.attemptreopenmethod = attemptreopenmethod\n",
    "        self.maxattempts = maxattempts\n",
    "        self.markingworkflow = markingworkflow\n",
    "        self.markingallocation = markingallocation\n",
    "        self.sendstudentnotifications = sendstudentnotifications\n",
    "        self.preventsubmissionnotingroup = preventsubmissionnotingroup\n",
    "        self.activity = activity\n",
    "        self.activityformat = activityformat\n",
    "        self.timelimit = timelimit\n",
    "        self.submissionattachments = submissionattachments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6fff98fc3b3d81bd655c2cc48858186e4d9e2db7b515bf1c3221888f12a62f87"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
